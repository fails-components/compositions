# Setting up fails using Docker compose
## Introduction
You can use the files in this directory to easily setup an installation of fails on a single computer using the *docker-compose* command. Or you can use this configuration as basis for a more complex setup using other container orchestration tools. For using Kubernetes please look into the helmchart directory. The file assumes that you a working knowledge of Docker and Docker compose

## Architecture of the Fails and the Docker compose setup
Fails is internally divided into several microservices, which we call handler.
Each is running in its own container.

Fails needs two database services:
- Mongo db, which stores users, lectures and lectures boards and does the bookkeeping of assests (including pictures, background pdfs)
- Redis db, which holds lecture boards and most configurations during a lecture and also manages private and public keys for authentification across all handlers. It also transports socket.io messages between different handlers
Both handlers are included as separated containers. Only Mongo db needs are backup, which is handled by a separate backup container (see documentation of the Backup container for details).

Additionally assets need to be stored. Assests are user uploaded data such as pictures or pdfs, which serve as background.
Assets can be either stored on a directory included into the Docker compose via a bind mount and served by the nginx container.
Alternatively, assets can be stored in an object storage service, that nowadays almost every cloud provider offers. (Currently, Openswift and S3 storage are supported, tested on Ovh (Openswift and S3) and OpenTelekomCloud(S3)).

Https traffic is routed by HA proxy, which 

The handlers microservices in details:
### ltihandler
Serves routes under `/lti/` and handles authentication against and LTI provider.
Currently, it is tested with moodle LMS, for which a plugin is available, which adds accesses proprietary a REST api on the LTI handler to inform fails of users, course and activity deletion. In this way the LMS can completely controll fails.
The ltihandler creates and JWT authentication token after the LTI authentification flow, which is later valid for the apphandler to access the fails inside the LMS.
You can configure the ltihandler to readonly mode, that effectively limits permissions to learner level and only allows pdf download.
For configuring the LTI handler in your LMS you have to use the following routes:
```
  Tool URL:
  https://thedomain.com/lti/launch

  Authentication URL:
  https://thedomain.com/lti/login

  Redirect URL:
  https://thedomain.com/lti/launch
```

In principle, it is not very difficult to write a replacement for the LTI handler, if a different frontend either standalone or for websites systems such as typo3 is desired.
  
### authhandler
It is possible to directly launch the fails main app (e.g. in a room with a Keyboard on a touch screen, where no private login to the lms is possible) and to authenticate with a login code or QR reader from the LTI activity on another device. 
The authhandler is connected via socket.io and a redis adapter to the apphandler authorizing the request.

### apphandler
Handles the REST api under route /app/ for the application inside the LTI activity in your LMS.
It is connected to assets, mongo db and redis.
It serves the raw data to the clients, e.g. for PDF generations. Note PDF are fully generated on client side and cause little load on the server.
Furthermore polls, pictures and other lecture and course configuration is handled by this component.

Authentification is done by the JWT Token generated by the ltihandler. It can also renew its token.
The apphandler also generates JWT Tokens for launching notepads and screens, handled by the notepadhandler.

### notepadhandler
Handles the running lectures for instructors (notepads as well as screens, notepads can write, screens just show content). 
It is connected via socket.io with the lectureapp.
Mainly the drawing commands are passed (to other notepads and screens, again via socket.io and redis adapter, as well as to student notes) and stored in redis databases. Boards are loaded during launch from mongo database. However the majority of settings reside inside the redis database during the lecture.
It handles the complete workflow during a lecture. 
It is authenticated using JWT tokens either generated from apphandler or from notepadhandler.
JWT token can be renewed.

### noteshandler
It is the same as notepadhandler but for students.
So it is read only for lecture notes and only managed additionally student activities such as polling, chat questions etc.
Separting instructors and students allows to control the container resources for instructors and students independently, which prevents disruptin of services for instructors due to many students using the software.

### housekeeping
Transfer lectures from redis to mongodb once a minutes. It also deletes lectures from redis.
It is also responsible for deleting lectures and assests from mongodb or assets, if the lecture owner and the LMS activity both are deleted.
Once container should be sufficient in any case.

### staticserver
An nginx based container serving files under /static/.
This includes the main apps 
- /static/app/ inside the LTI and 
- /static/lecture/ during the lecture

as well as open source licenses
- /static/oss/
and optionally serves assets using secured links with limited temporal validity.



## Specific setup instructions
First step is to create a *.env* files with the configuration variables:
```
FAILS_TAG="master" # optional tag of fails container, either a version tag or a branch tag,
#  decides with containers to use, you can also use a version tag such as v1 or v1.1 or v1.1.1

FAILS_KEYS_SECRET="YOURKEYFORJWTKEYGENERATION"
# Static secret only required, if the assets are served via nginx
FAILS_STATIC_SECRET="ASECRETFORUSERUPLOADEDASSETSWITHSECUREDURLS"
# Choose the type of storage for your assets "nginx" (default) or "openstackswift"
FAILS_STATIC_WEBSERV_TYPE="nginx"
# were to save your static file, "fs" (default) for filesystem, or "openstackswift"
FAILS_STATIC_SAVE_TYPE="fs"

# If you use swift storage set the following variables
#FAILS_SWIFT_ACCOUNT="Accountnameofyourswiftbucket"
#FAILS_SWIFT_CONTAINER="ContainerNameofYourURL"
#FAILS_SWIFT_KEY="KeyUsedForSignedURLsForYourSwiftStorage"
#FAILS_SWIFT_BASEURL="https://somestorageprovider.org"
#FAILS_SWIFT_USERNAME="UserNameForAccessingYourBucket"
#FAILS_SWIFT_PASSWORD="PasswordForYourUserName"
#FAILS_SWIFT_AUTH_BASEURL = "https://auth.somestorageprovider.org"
#FAILS_SWIFT_DOMAIN="DomainForYourStorage"
#FAILS_SWIFT_PROJECT="ProjectForYourStorage"

# if you use s3 storage set the following values
FAILS_S3_AK="AKFORKEYGENERATION"
FAILS_S3_SK="SKFORKEYGENERATION"
FAILS_S3_REGION="youregion"
FAILS_S3_BUCKET="yourbucket"
FAILS_S3_HOST="hostofyours3provider"
FAILS_S3_ALTURL="alternativehostnameforyoururls"


FAILS_LMS_LIST="TOPUNIVERSITY|https://yourschool.edu/lti/certs.php|https:/yourschool.edu/lti/token.php|https://yourschool.edu/lti/auth.php|yourschool.edu/ TOPUNIVERSITY2|https://yourschool2.edu/lti/certs.php|https:/yourschool2.edu/lti/token.php|https://yourschool2.edu/lti/auth.php|yourschool2.edu/"
# you can pipe custom support contact info and messages into the system for the lms app
FAILS_APP_CONFIG_JSON="{\"support\": { \"text\": \"Please contact our support at\", \"url\": \"https://fabolous-support.de\"}, \"maintenance\": {\"message\": \"The system is going for maintenace at\"}}"


REDIS_DATA_DIR="/path/to/your/redis/db"
REDIS_PASS="yourredispassword"
# Specifiy the docker volume for your mongo db
# note you have to setup a database `fails` inside the mongodb directory 
# and set username and password manually
MONGO_DATA_VOLUME="volumeforyourmongodb"
MONGO_BACKUP_DIR="/path/to/your/mongodb/backup"
MONGO_USER="usernameforfailsinmongodb"
MONGO_PASS="passwordforthisuser"
#MONGO_OPTIONS="--wiredTigerCacheSizeGB 0.5"

# must also be provided, if not stored on file system, but then the dir can be empty
ASSETS_DATA_DIR="/path/to/your/users/assets"

FAILS_COOKIE_KEY="keytogeneratecookiesforstickysessioninloadbalancing"

CERT_FILE="/path/to/your/certificate/file/cert.pem"

FAILS_LMS_COURSE_WHITELIST="9999 8888"
FAILS_HTTP_PORT=80
FAILS_HTTPS_PORT=443

```
*FAILS_LMS_COURSE_WHITELIST* should only be used, if you want to use a whitelist, this is perfect for a limited beta test. *FAILS_HTTP_PORT* and *FAILS_HTTPS_PORT* should only be used, if they differ from the default ports.
You can find more details about the configuration variables in the *docker-compose.yml* file or in the source code of the components.

You can pull and build the container images (also updates the container software):
```
docker compose build
docker compose pull
```

You can fire the fails server up (or restart with updated containers) with:
```
docker compose up -d
```
if you have a working docker installation with docker compose.
